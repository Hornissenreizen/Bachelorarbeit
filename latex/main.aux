\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Model Framework}{3}{section.1}\protected@file@percent }
\newlabel{lemma:random_variables_do_not_change_with_future_models}{{1.1}{4}{}{lemma.1.1}{}}
\newlabel{def:induced_bulk_marginal_model}{{1.3}{4}{Induced Bulk Marginal Model}{definition.1.3}{}}
\newlabel{definition:strong_model_power_law_behavior}{{1.6}{5}{Strong Power-Law Behavior}{definition.1.6}{}}
\newlabel{definition:weak_power_law_behavior}{{1.8}{6}{Weak Power-Law Behavior}{definition.1.8}{}}
\newlabel{theorem:power_law_decay_in_well-behaved_models_with_weak_power-law_behavior}{{1.1}{6}{Every Token has Power-Law Decay in Models with the Bulk Marginal Property and Weak Power-Law Behavior}{theorem.1.1}{}}
\newlabel{proposition:strong_slbplb_implies_wlbplb}{{1.2}{7}{}{proposition.1.2}{}}
\newlabel{definition:large_scale_time_invariance}{{1.9}{7}{}{definition.1.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Mutual Information in Markov Chains}{8}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Exponential Decay in Irreducible Aperiodic Markov Chains}{8}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple irreducible aperiodic Markov chain. Note that if $X_{t_0} = C$, then we know that $X_{t_0+1} = A$.}}{9}{figure.1}\protected@file@percent }
\newlabel{fig:2_markov_chain}{{1}{9}{A simple irreducible aperiodic Markov chain. Note that if $X_{t_0} = C$, then we know that $X_{t_0+1} = A$}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}The Defective Case}{13}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{section:the_defectvie_case}{{2.1.1}{13}{The Defective Case}{subsubsection.2.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}No Markov Chain with Power-Law Behavior}{14}{subsection.2.2}\protected@file@percent }
\newlabel{theorem:no_markov_chain_with_power-law_behavior}{{2.2}{15}{No Markov Chain with Power-Law Behavior}{theorem.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}No Power-Law in Hidden Markov Models}{17}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Bayesian network of Markov chains. All arrows go from previous tokens to future tokens.}}{17}{figure.2}\protected@file@percent }
\newlabel{fig:bayesian_network_markov_chain}{{2}{17}{Bayesian network of Markov chains. All arrows go from previous tokens to future tokens}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Bayesian network of a hidden Markov model.}}{18}{figure.3}\protected@file@percent }
\newlabel{fig:bayesian_network_hidden_markov}{{3}{18}{Bayesian network of a hidden Markov model}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Adjusted Bayesian network of a hidden Markov model.}}{20}{figure.4}\protected@file@percent }
\newlabel{fig:adjusted_bayesian_network_hidden_markov}{{4}{20}{Adjusted Bayesian network of a hidden Markov model}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Conclusions for Model Selection}{21}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Tensor Networks}{23}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A basic tensor network over $\Sigma ^3$.}}{24}{figure.5}\protected@file@percent }
\newlabel{lemma:normalized_tensor_networks}{{4.1}{25}{}{lemma.4.1}{}}
\newlabel{proposition:contracting_over_shared_index}{{4.1}{27}{}{proposition.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Contracting multiple tensors over one shared index is equivalent to contracting them individually with a single copy tensor.}}{28}{figure.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Binary Tree Tensor Networks}{29}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Binary tree model space for sequences of length $n = 2^k$.}}{29}{figure.7}\protected@file@percent }
\newlabel{fig:binary_tree_tensor_network}{{7}{29}{Binary tree model space for sequences of length $n = 2^k$}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Bulk Marginal Property}{29}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Bulk marginal property enforces the equivalence of these models.}}{30}{figure.8}\protected@file@percent }
\newlabel{fig:bmp_model_equiv}{{8}{30}{Bulk marginal property enforces the equivalence of these models}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Contracting this sub-network with all-ones vectors yields vector $\bm  {v}$.}}{30}{figure.9}\protected@file@percent }
\newlabel{fig:sufficient_condition_bmp}{{9}{30}{Contracting this sub-network with all-ones vectors yields vector $\bm {v}$}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Binary Tree Tensor Networks are Universal Approximators}{31}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Model structure of binary tree tensor networks for $n = 2^k = 4$.}}{32}{figure.10}\protected@file@percent }
\newlabel{fig:binary_tree_tensor_network_n_equals_four}{{10}{32}{Model structure of binary tree tensor networks for $n = 2^k = 4$}{figure.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Restricting Parameters}{32}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Markov Chains}{35}{appendix.A}\protected@file@percent }
\newlabel{section:markov_chains}{{A}{35}{Markov Chains}{appendix.A}{}}
\newlabel{ex:markov_chain}{{A.1}{35}{Markov Transition Matrix}{example.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Properties}{36}{subsection.A.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Graph representation of the Markov chain defined in example~\ref {ex:markov_chain}.}}{37}{figure.11}\protected@file@percent }
\newlabel{fig:markov_chain}{{11}{37}{Graph representation of the Markov chain defined in example~\ref {ex:markov_chain}}{figure.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.1}Irreducibility}{37}{subsubsection.A.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Graph of a reducible Markov chain. Note that once the chain transitions from state $1$ to state $3$, it will stay at state $3$ indefinitely.}}{37}{figure.12}\protected@file@percent }
\newlabel{fig:markov_chain_reducible}{{12}{37}{Graph of a reducible Markov chain. Note that once the chain transitions from state $1$ to state $3$, it will stay at state $3$ indefinitely}{figure.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.1.2}Aperiodicity}{39}{subsubsection.A.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Graph of a periodic Markov chain. Note that once once the starting position is determined, then we also know the state after $t$ steps.}}{39}{figure.13}\protected@file@percent }
\newlabel{fig:markov_chain_periodic}{{13}{39}{Graph of a periodic Markov chain. Note that once once the starting position is determined, then we also know the state after $t$ steps}{figure.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Irreducible Aperiodic Markov Chains}{40}{subsection.A.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Graph of a reducible Markov chain with two closed communication classes. Note that we might end up stuck at either state $2$ or state $3$.}}{41}{figure.14}\protected@file@percent }
\newlabel{fig:markov_chain_two_closed_classes}{{14}{41}{Graph of a reducible Markov chain with two closed communication classes. Note that we might end up stuck at either state $2$ or state $3$}{figure.14}{}}
\newlabel{theorem:positive_transition_matrix}{{A.3}{41}{Positive n-Step Transition Matrix for Irreducible Aperiodic Markov Chains}{theorem.A.3}{}}
\newlabel{lemma:aux}{{A.4}{41}{}{lemma.A.4}{}}
\newlabel{remark:converse_lemma_aux}{{A.5}{41}{}{remark.A.5}{}}
\newlabel{corollary:converse_positive_transition_matrix}{{A.2}{42}{}{corollary.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Perron-Frobenius Theorem}{42}{subsection.A.3}\protected@file@percent }
\newlabel{theorem:perron_frobenius}{{A.4}{42}{Perron-Frobenius}{theorem.A.4}{}}
\newlabel{corollary:perron_frobenius_extension}{{A.3}{44}{Extension to More General Markov Chains}{corollary.A.3}{}}
\newlabel{lemma:perron_frobenius_extension_A_to_the_m}{{A.5}{44}{}{lemma.A.5}{}}
\newlabel{remark:exponential_decay}{{A.7}{45}{}{remark.A.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Information Theory}{46}{appendix.B}\protected@file@percent }
\newlabel{section:information_theory}{{B}{46}{Information Theory}{appendix.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Entropy}{46}{subsection.B.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Plot of the function $y=-x\ln (x)$.}}{46}{figure.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.1.1}Joint, Conditional, and Cross Entropy}{48}{subsubsection.B.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.1.2}Properties of Entropy}{49}{subsubsection.B.1.2}\protected@file@percent }
\newlabel{proposition:entropy_conditional}{{B.3}{49}{}{proposition.B.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Kullback-Leibler Divergence}{51}{subsection.B.2}\protected@file@percent }
\newlabel{sec:kullback_leibler_divergence}{{B.2}{51}{Kullback-Leibler Divergence}{subsection.B.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Mutual Information}{53}{subsection.B.3}\protected@file@percent }
\newlabel{sec:mutual_information}{{B.3}{53}{Mutual Information}{subsection.B.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.3.1}Data Processing Inequality}{56}{subsubsection.B.3.1}\protected@file@percent }
\newlabel{theorem:data_processing_inequality}{{B.3}{56}{Data Processing Inequality}{theorem.B.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}Bounding Mutual Information via Matrix Rank of the Joint Distribution}{57}{subsection.B.4}\protected@file@percent }
\gdef \@abspage@last{57}
