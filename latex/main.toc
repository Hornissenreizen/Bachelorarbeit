\contentsline {section}{\numberline {1}Model Framework}{4}{section.1}%
\contentsline {section}{\numberline {2}A Model with Power-Law Behavior}{9}{section.2}%
\contentsline {subsection}{\numberline {2.1}The Model}{9}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}A Formula for Mutual Information}{9}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Initializing Parameters}{11}{subsubsection.2.1.2}%
\contentsline {subsubsection}{\numberline {2.1.3}Ensure Positive Definiteness}{12}{subsubsection.2.1.3}%
\contentsline {subsubsection}{\numberline {2.1.4}Strong Power-Law Behavior}{14}{subsubsection.2.1.4}%
\contentsline {subsection}{\numberline {2.2}Summary}{20}{subsection.2.2}%
\contentsline {section}{\numberline {3}Mutual Information in Markov Chains}{21}{section.3}%
\contentsline {subsection}{\numberline {3.1}Exponential Decay in Irreducible Aperiodic Markov Chains}{21}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}The Defective Case}{26}{subsubsection.3.1.1}%
\contentsline {subsection}{\numberline {3.2}No Markov Chain with Power-Law Behavior}{27}{subsection.3.2}%
\contentsline {section}{\numberline {4}No Power-Law in Hidden Markov Models}{30}{section.4}%
\contentsline {subsection}{\numberline {4.1}Conclusions for Model Selection}{37}{subsection.4.1}%
\contentsline {section}{\numberline {5}Binary Tree Tensor Networks}{39}{section.5}%
\contentsline {subsection}{\numberline {5.1}Bulk Marginal Property}{39}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Binary Tree Tensor Networks are Universal Approximators}{41}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Restricting Parameters}{42}{subsection.5.3}%
\contentsline {subsubsection}{\numberline {5.3.1}PCBTTN Aren't Universal Approximators}{43}{subsubsection.5.3.1}%
\contentsline {subsubsection}{\numberline {5.3.2}Power-Law Behavior in PCBTTN}{44}{subsubsection.5.3.2}%
\contentsline {section}{\numberline {A}Markov Chains}{47}{appendix.A}%
\contentsline {subsection}{\numberline {A.1}Properties}{48}{subsection.A.1}%
\contentsline {subsubsection}{\numberline {A.1.1}Irreducibility}{49}{subsubsection.A.1.1}%
\contentsline {subsubsection}{\numberline {A.1.2}Aperiodicity}{51}{subsubsection.A.1.2}%
\contentsline {subsection}{\numberline {A.2}Irreducible Aperiodic Markov Chains}{53}{subsection.A.2}%
\contentsline {subsection}{\numberline {A.3}Perron-Frobenius Theorem}{54}{subsection.A.3}%
\contentsline {section}{\numberline {B}Information Theory}{58}{appendix.B}%
\contentsline {subsection}{\numberline {B.1}Entropy}{58}{subsection.B.1}%
\contentsline {subsubsection}{\numberline {B.1.1}Joint, Conditional, and Cross Entropy}{60}{subsubsection.B.1.1}%
\contentsline {subsubsection}{\numberline {B.1.2}Properties of Entropy}{61}{subsubsection.B.1.2}%
\contentsline {subsection}{\numberline {B.2}Kullback-Leibler Divergence}{63}{subsection.B.2}%
\contentsline {subsection}{\numberline {B.3}Mutual Information}{65}{subsection.B.3}%
\contentsline {subsubsection}{\numberline {B.3.1}Data Processing Inequality}{68}{subsubsection.B.3.1}%
\contentsline {subsection}{\numberline {B.4}Bounding Mutual Information via Matrix Rank of the Joint Distribution}{69}{subsection.B.4}%
\contentsline {subsection}{\numberline {B.5}Convergence of Mutual Information}{70}{subsection.B.5}%
\contentsline {section}{\numberline {C}Tensor Networks}{74}{appendix.C}%
\contentsline {subsection}{\numberline {C.1}Reshaping a Tensor (Matricization)}{79}{subsection.C.1}%
\contentsline {subsubsection}{\numberline {C.1.1}An Upper Bound for the Rank of Matrices in Tensor Networks}{79}{subsubsection.C.1.1}%
